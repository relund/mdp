% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mdp.R
\name{runPolicyIteAve}
\alias{runPolicyIteAve}
\title{Perform policy iteration (average reward criterion) on the MDP.}
\usage{
runPolicyIteAve(mdp, w, dur, maxIte = 100, getLog = TRUE)
}
\arguments{
\item{mdp}{The MDP loaded using \code{\link[=loadMDP]{loadMDP()}}.}

\item{w}{The label of the weight we optimize.}

\item{dur}{The label of the duration/time such that discount rates can be calculated.}

\item{maxIte}{Max number of iterations. If the model does not satisfy the unichain assumption the algorithm may loop.}

\item{getLog}{Output the log messages.}
}
\value{
The optimal gain (g) calculated.
}
\description{
The policy can afterwards be received using functions \code{getPolicy} and \code{getPolicyW}.
}
\seealso{
\code{\link[=getPolicy]{getPolicy()}}.
}
