<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="MDP2">
<title>Solving an infinite-horizon semi-MDP • MDP2</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Solving an infinite-horizon semi-MDP">
<meta property="og:description" content="MDP2">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">MDP2</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.1.2</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/building.html">Building an MDP model</a>
    <a class="dropdown-item" href="../articles/finite-mdp.html">Solving a finite-horizon semi-MDP</a>
    <a class="dropdown-item" href="../articles/infinite-hmdp.html">An infinite-horizon HMDP</a>
    <a class="dropdown-item" href="../articles/infinite-mdp.html">Solving an infinite-horizon semi-MDP</a>
    <a class="dropdown-item" href="../articles/mdp2.html">The MDP2 package</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/relund/mdp/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Solving an infinite-horizon semi-MDP</h1>
                        <h4 data-toc-skip class="author">Lars Relund <a href="mailto:lars@relund.dk" class="email">lars@relund.dk</a>
</h4>
            
            <h4 data-toc-skip class="date">2023-01-29</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/relund/mdp/blob/HEAD/vignettes/infinite-mdp.Rmd" class="external-link"><code>vignettes/infinite-mdp.Rmd</code></a></small>
      <div class="d-none name"><code>infinite-mdp.Rmd</code></div>
    </div>

    
    
<style> 
p {text-align: justify;} 
//.sourceCode {background-color: white;}
pre {
  // border-style: solid;
  // border-width: 1px;
  // border-color: grey;
  //background-color: grey !important;
}
img {
   //width: 100%;
   border: 0;
}
</style>
<!-- scale math down --><script type="text/x-mathjax-config"> 
    MathJax.Hub.Config({ 
        "HTML-CSS": { scale: 80 }
        });
</script><p>The <code>MDP2</code> package in R is a package for solving Markov
decision processes (MDPs) with discrete time-steps, states and actions.
Both traditional MDPs <span class="citation">(Puterman 1994)</span>,
semi-Markov decision processes (semi-MDPs) <span class="citation">(Tijms
2003)</span> and hierarchical-MDPs (HMDPs) <span class="citation">(Kristensen and Jørgensen 2000)</span> can be solved
under a finite and infinite time-horizon.</p>
<p>The package implement well-known algorithms such as policy iteration
and value iteration under different criteria e.g. average reward per
time unit and expected total discounted reward. The model is stored
using an underlying data structure based on the <em>state-expanded
directed hypergraph</em> of the MDP (<span class="citation">Nielsen and
Kristensen (2006)</span>) implemented in <code>C++</code> for fast
running times. <!-- Under development is also
support for MLHMP which is a Java implementation of algorithms for solving MDPs (@Kristensen03). 
--></p>
<p>Building and solving an MDP is done in two steps. First, the MDP is
built and saved in a set of binary files. Next, you load the MDP into
memory from the binary files and apply various algorithms to the
model.</p>
<p>For building the MDP models see <code><a href="../articles/building.html">vignette("building")</a></code>. In
this vignette we focus on the second step, i.e. finding the optimal
policy. Here we consider an infinite semi-MDP.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://relund.github.io/mdp/" class="external-link">MDP2</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="an-infinite-horizon-semi-mdp">An infinite-horizon semi-MDP<a class="anchor" aria-label="anchor" href="#an-infinite-horizon-semi-mdp"></a>
</h2>
<p>An <em>infinite-horizon semi-MDP</em> considers a sequential decision
problem over an infinite number of <em>stages</em>. Let <span class="math inline">\(I\)</span> denote the finite set of system states
at stage <span class="math inline">\(n\)</span>. Note we assume that the
semi-MDP is <em>homogeneous</em>, i.e the state space is independent of
stage number. When <em>state</em> <span class="math inline">\(i \in
I\)</span> is observed, an <em>action</em> <span class="math inline">\(a\)</span> from the finite set of allowable
actions <span class="math inline">\(A(i)\)</span> must be chosen which
generates <em>reward</em> <span class="math inline">\(r(i,a)\)</span>.
Moreover, let <span class="math inline">\(\tau(i,a)\)</span> denote the
<em>stage length</em> of action <span class="math inline">\(a\)</span>,
i.e. the expected time until the next decision epoch (stage <span class="math inline">\(n+1\)</span>) given action <span class="math inline">\(a\)</span> and state <span class="math inline">\(i\)</span>. Finally, let <span class="math inline">\(p_{ij}(a)\)</span> denote the <em>transition
probability</em> of obtaining state <span class="math inline">\(j\in
I\)</span> at stage <span class="math inline">\(n+1\)</span> given that
action <span class="math inline">\(a\)</span> is chosen in state <span class="math inline">\(i\)</span> at stage <span class="math inline">\(n\)</span>. A policy is a decision rule/function
that assigns to each state in the process an action.</p>
</div>
<div class="section level2">
<h2 id="example">Example<a class="anchor" aria-label="anchor" href="#example"></a>
</h2>
<p>Let us consider example 6.1.1 in <span class="citation">Tijms
(2003)</span>. At the beginning of each day a piece of equipment is
inspected to reveal its actual working condition. The equipment will be
found in one of the working conditions <span class="math inline">\(i =
1,\ldots, N\)</span> where the working condition <span class="math inline">\(i\)</span> is better than the working condition
<span class="math inline">\(i+1\)</span>. The equipment deteriorates in
time. If the present working condition is <span class="math inline">\(i\)</span> and no repair is done, then at the
beginning of the next day the equipment has working condition <span class="math inline">\(j\)</span> with probability <span class="math inline">\(q_{ij}\)</span>. It is assumed that <span class="math inline">\(q_{ij}=0\)</span> for <span class="math inline">\(j&lt;i\)</span> and <span class="math inline">\(\sum_{j\geq i}q_{ij}=1\)</span>. The working
condition <span class="math inline">\(i=N\)</span> represents a
malfunction that requires an enforced repair taking two days. For the
intermediate states <span class="math inline">\(i\)</span> with <span class="math inline">\(1&lt;i&lt;N\)</span> there is a choice between
preventively repairing the equipment and letting the equipment operate
for the present day. A preventive repair takes only one day. A repaired
system has the working condition <span class="math inline">\(i=1\)</span>. The cost of an enforced repair upon
failure is <span class="math inline">\(C_{f}\)</span> and the cost of a
preemptive repair in working condition <span class="math inline">\(i\)</span> is <span class="math inline">\(C_{p}(i)\)</span>. We wish to determine a
maintenance rule which minimizes the long-run average repair cost per
day.</p>
<p>To formulate this problem as an infinite horizon semi-MDP the set of
possible states of the system is chosen as <span class="math display">\[
I=\{1,2,\ldots,N\}.
\]</span> State <span class="math inline">\(i\)</span> corresponds to
the situation in which an inspection reveals working condition <span class="math inline">\(i\)</span>. Define actions <span class="math display">\[
a=\left\{\begin{array}{ll}
nr &amp; \text{if no repair.}\\
pr &amp; \text{if preventive repair.}\\
fr &amp; \text{if forced repair.}\\
\end{array}\right.
\]</span> The set of possible actions in state <span class="math inline">\(i\)</span> is chosen as <span class="math inline">\(A(1)=\{nr\},\ A(i)=\{nr,pr\}\)</span> for <span class="math inline">\(1&lt;i&lt;N, A(N)=\{fr\}\)</span>. The one-step
transition probabilities <span class="math inline">\(p_{ij}(a)\)</span>
are given by <span class="math inline">\(p_{ij}(0) = q_{ij}\)</span> for
<span class="math inline">\(1\leq i&lt;N\)</span>, <span class="math inline">\(p_{i1}(1) = 1\)</span> for <span class="math inline">\(1&lt;i&lt;N\)</span>, <span class="math inline">\(p_{N1}(2)=1\)</span> and zero otherwise. The
one-step costs <span class="math inline">\(c_{i}(a)\)</span> are given
by <span class="math inline">\(c_{i}(0)=0,\ c_{i}(1)=C_{p}(i)\)</span>
and <span class="math inline">\(c_{N}(2)=C_{f}\)</span>. The stage
length until next decision epoch are <span class="math inline">\(\tau(i,a) = 1, 0\leq i &lt; N\)</span> and <span class="math inline">\(\tau(N,a) = 2\)</span>.</p>
<p>Assume that the number of possible working conditions equals <span class="math inline">\(N=5\)</span>. The repair costs are given by <span class="math inline">\(C_{f}=10,\ C_{p}(2)=7,\ C_{p}(3)=7\)</span> and
<span class="math inline">\(C_{p}(4)=5\)</span>. The deterioration
probabilities <span class="math inline">\(q_{ij}\)</span> are given
by</p>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="right">1</th>
<th align="right">2</th>
<th align="right">3</th>
<th align="right">4</th>
<th align="right">5</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="right">0.9</td>
<td align="right">0.1</td>
<td align="right">0.0</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="right">0.0</td>
<td align="right">0.8</td>
<td align="right">0.1</td>
<td align="right">0.05</td>
<td align="right">0.05</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="right">0.0</td>
<td align="right">0.0</td>
<td align="right">0.7</td>
<td align="right">0.10</td>
<td align="right">0.20</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="right">0.0</td>
<td align="right">0.0</td>
<td align="right">0.0</td>
<td align="right">0.50</td>
<td align="right">0.50</td>
</tr>
</tbody>
</table>
<p>For building and saving the model see the
<code><a href="../articles/building.html">vignette("building")</a></code>. We load the model using</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prefix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/system.file.html" class="external-link">system.file</a></span><span class="op">(</span><span class="st">"models"</span>, package <span class="op">=</span> <span class="st">"MDP2"</span><span class="op">)</span>, <span class="st">"/hct611-1_"</span><span class="op">)</span></span>
<span><span class="va">mdp</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/loadMDP.html">loadMDP</a></span><span class="op">(</span><span class="va">prefix</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; Read binary files (0.000144899 sec.)</span></span>
<span><span class="co">#&gt; Build the HMDP (3.17e-05 sec.)</span></span></code></pre>
<pre><code><span><span class="co">#&gt; Checking MDP and found no errors (1.1e-06 sec.)</span></span></code></pre>
<p>The variable <code>mdp</code> is a list with a pointer to the MDP
object stored in memory.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mdp</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; $binNames</span></span>
<span><span class="co">#&gt; [1] "/home/runner/work/_temp/Library/MDP2/models/hct611-1_stateIdx.bin"         </span></span>
<span><span class="co">#&gt; [2] "/home/runner/work/_temp/Library/MDP2/models/hct611-1_stateIdxLbl.bin"      </span></span>
<span><span class="co">#&gt; [3] "/home/runner/work/_temp/Library/MDP2/models/hct611-1_actionIdx.bin"        </span></span>
<span><span class="co">#&gt; [4] "/home/runner/work/_temp/Library/MDP2/models/hct611-1_actionIdxLbl.bin"     </span></span>
<span><span class="co">#&gt; [5] "/home/runner/work/_temp/Library/MDP2/models/hct611-1_actionWeight.bin"     </span></span>
<span><span class="co">#&gt; [6] "/home/runner/work/_temp/Library/MDP2/models/hct611-1_actionWeightLbl.bin"  </span></span>
<span><span class="co">#&gt; [7] "/home/runner/work/_temp/Library/MDP2/models/hct611-1_transProb.bin"        </span></span>
<span><span class="co">#&gt; [8] "/home/runner/work/_temp/Library/MDP2/models/hct611-1_externalProcesses.bin"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $timeHorizon</span></span>
<span><span class="co">#&gt; [1] Inf</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $states</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $founderStatesLast</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $actions</span></span>
<span><span class="co">#&gt; [1] 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $levels</span></span>
<span><span class="co">#&gt; [1] 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $weightNames</span></span>
<span><span class="co">#&gt; [1] "Duration"   "Net reward"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $ptr</span></span>
<span><span class="co">#&gt; C++ object &lt;0x558a0f0f1050&gt; of class 'HMDP' &lt;0x558a105dd250&gt;</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attr(,"class")</span></span>
<span><span class="co">#&gt; [1] "HMDP" "list"</span></span></code></pre>
<p>For instance the total number of actions is 8 and the model use two
weights applied to each action “Duration” and “Net reward”. Information
about the MDP can be retrieved using <code><a href="../reference/getInfo.html">getInfo()</a></code>:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/getInfo.html">getInfo</a></span><span class="op">(</span><span class="va">mdp</span>, withList <span class="op">=</span> <span class="cn">F</span>, dfLevel <span class="op">=</span> <span class="st">"action"</span>, asStringsActions <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>  </span></code></pre></div>
<pre><code><span><span class="co">#&gt; $df</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 8 × 8</span></span></span>
<span><span class="co">#&gt;     sId stateStr label  aIdx label_action      weights trans   pr               </span></span>
<span><span class="co">#&gt;   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>             <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>            </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">1</span>     5 0,0      i=1       0 no repair         1,0     0,1     0.9,0.1          </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">2</span>     6 0,1      i=2       0 no repair         1,0     1,2,3,4 0.8,0.1,0.05,0.05</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">3</span>     6 0,1      i=2       1 preventive repair 1,-7    0       1                </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">4</span>     7 0,2      i=3       0 no repair         1,0     2,3,4   0.7,0.1,0.2      </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">5</span>     7 0,2      i=3       1 preventive repair 1,-7    0       1                </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">6</span>     8 0,3      i=4       0 no repair         1,0     3,4     0.5,0.5          </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">7</span>     8 0,3      i=4       1 preventive repair 1,-5    0       1                </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">8</span>     9 0,4      i=5       0 forced repair     2,-10   0       1</span></span></code></pre>
<p>Here the tibble has a row for each state and action. For instance the
weight “Duration” equals 1 day except in state <span class="math inline">\(i=5\)</span> where a forced repair takes 2 days
(row 13). States with no actions are also given.</p>
<p>The state-expanded hypergraph representing the semi-MDP with infinite
time-horizon can be plotted using</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mdp</span>, hyperarcColor <span class="op">=</span> <span class="st">"label"</span>, nodeLabel <span class="op">=</span> <span class="st">"sId:label"</span><span class="op">)</span></span></code></pre></div>
<p><img src="infinite-mdp_files/figure-html/plotHgf-1.png" width="864" style="max-width:100%;"></p>
<p>Each node corresponds to a specific state in the MDP and is a
<em>unique id</em> (<code>sId</code>) such that you can identify all the
states (<strong>id always start from zero</strong>). These ids are not
equal to the ids used when you built the model, since the order of the
nodes in the hypergraph data structure is optimized! A directed hyperarc
is defined for each possible action. For instance, the state/node with
<code>sId = 6</code> corresponds to working condition <span class="math inline">\(i=2\)</span> and the two hyperarcs with head in
this node corresponds to the two actions preventive and no repair. Note
the tails of a hyperarc represent a possible transition (<span class="math inline">\(p_{ij}(a)&gt;0\)</span>).</p>
<p>Given the model in memory, we now can find the optimal policy under
various policies. Let us first try to optimize the average reward per
time unit.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/runPolicyIteAve.html">runPolicyIteAve</a></span><span class="op">(</span><span class="va">mdp</span>,<span class="st">"Net reward"</span>,<span class="st">"Duration"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; Run policy iteration under average reward criterion using </span></span>
<span><span class="co">#&gt; reward 'Net reward' over 'Duration'. Iterations (g): </span></span>
<span><span class="co">#&gt; 1 (-0.512821) 2 (-0.446154) 3 (-0.43379) 4 (-0.43379) finished. Cpu time: 1.1e-06 sec.</span></span></code></pre>
<pre><code><span><span class="co">#&gt; [1] -0.43379</span></span></code></pre>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/getPolicy.html">getPolicy</a></span><span class="op">(</span><span class="va">mdp</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 5 × 6</span></span></span>
<span><span class="co">#&gt;     sId stateStr stateLabel  aIdx actionLabel       weight</span></span>
<span><span class="co">#&gt;   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>      <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>              <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">1</span>     5 0,0      i=1            0 no repair           9.13</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">2</span>     6 0,1      i=2            0 no repair           4.79</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">3</span>     7 0,2      i=3            0 no repair           2.97</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">4</span>     8 0,3      i=4            1 preventive repair   4.57</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">5</span>     9 0,4      i=5            0 forced repair       0</span></span></code></pre>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mdp</span>, hyperarcShow <span class="op">=</span> <span class="st">"policy"</span><span class="op">)</span></span></code></pre></div>
<p><img src="infinite-mdp_files/figure-html/solve1_ave-1.png" width="864" style="max-width:100%;"></p>
<p>Note it is optimal to do a preventive repair in state <span class="math inline">\(i=4\)</span>. Let us try to optimize the expected
total discounted reward with a discount factor of 0.5 using policy
iteration:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/runPolicyIteDiscount.html">runPolicyIteDiscount</a></span><span class="op">(</span><span class="va">mdp</span>,<span class="st">"Net reward"</span>,<span class="st">"Duration"</span>, discountFactor <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; Run policy iteration using quantity 'Net reward' under discounting criterion </span></span>
<span><span class="co">#&gt; with 'Duration' as duration using discount factor 0.5. </span></span>
<span><span class="co">#&gt; Iteration(s): 1 2 finished. Cpu time: 1.1e-06 sec.</span></span></code></pre>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/getPolicy.html">getPolicy</a></span><span class="op">(</span><span class="va">mdp</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 5 × 6</span></span></span>
<span><span class="co">#&gt;     sId stateStr stateLabel  aIdx actionLabel     weight</span></span>
<span><span class="co">#&gt;   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>      <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>            <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">1</span>     5 0,0      i=1            0 no repair      -<span style="color: #BB0000;">0.064</span><span style="color: #BB0000; text-decoration: underline;">2</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">2</span>     6 0,1      i=2            0 no repair      -<span style="color: #BB0000;">0.706</span> </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">3</span>     7 0,2      i=3            0 no repair      -<span style="color: #BB0000;">1.80</span>  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">4</span>     8 0,3      i=4            0 no repair      -<span style="color: #BB0000;">3.34</span>  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">5</span>     9 0,4      i=5            0 forced repair -<span style="color: #BB0000;">10.0</span></span></span></code></pre>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mdp</span>, hyperarcShow <span class="op">=</span> <span class="st">"policy"</span><span class="op">)</span></span></code></pre></div>
<p><img src="infinite-mdp_files/figure-html/unnamed-chunk-5-1.png" width="864" style="max-width:100%;"></p>
<p>Note given a discount factor of 0.5, it is optimal to not do a
preventive repair in state <span class="math inline">\(i=4\)</span>. The
same results can be found using value iteration:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/runValueIte.html">runValueIte</a></span><span class="op">(</span><span class="va">mdp</span>,<span class="st">"Net reward"</span>,<span class="st">"Duration"</span>, discountFactor <span class="op">=</span> <span class="fl">0.5</span>, eps <span class="op">=</span> <span class="fl">1e-10</span>, maxIte <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; Run value iteration with epsilon = 1e-10 at most 1000 time(s)</span></span>
<span><span class="co">#&gt; using quantity 'Net reward' under expected discounted reward criterion </span></span>
<span><span class="co">#&gt; with 'Duration' as duration using discount factor 0.5.</span></span>
<span><span class="co">#&gt; Iterations: 33 Finished. Cpu time 2.56e-05 sec.</span></span></code></pre>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/getPolicy.html">getPolicy</a></span><span class="op">(</span><span class="va">mdp</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 5 × 6</span></span></span>
<span><span class="co">#&gt;     sId stateStr stateLabel  aIdx actionLabel     weight</span></span>
<span><span class="co">#&gt;   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>      <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>            <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">1</span>     5 0,0      i=1            0 no repair      -<span style="color: #BB0000;">0.064</span><span style="color: #BB0000; text-decoration: underline;">2</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">2</span>     6 0,1      i=2            0 no repair      -<span style="color: #BB0000;">0.706</span> </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">3</span>     7 0,2      i=3            0 no repair      -<span style="color: #BB0000;">1.80</span>  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">4</span>     8 0,3      i=4            0 no repair      -<span style="color: #BB0000;">3.34</span>  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">5</span>     9 0,4      i=5            0 forced repair -<span style="color: #BB0000;">10.0</span></span></span></code></pre>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Kristensen00" class="csl-entry">
Kristensen, A. R., and E. Jørgensen. 2000. <span>“Multi-Level Hierarchic
<span>M</span>arkov Processes as a Framework for Herd Management
Support.”</span> <em>Annals of Operations Research</em> 94: 69–89. <a href="https://doi.org/10.1023/A:1018921201113" class="external-link">https://doi.org/10.1023/A:1018921201113</a>.
</div>
<div id="ref-Relund06" class="csl-entry">
Nielsen, L. R., and A. R. Kristensen. 2006. <span>“Finding the
<span><span class="math inline">\(K\)</span></span> Best Policies in a
Finite-Horizon <span>M</span>arkov Decision Process.”</span>
<em>European Journal of Operational Research</em> 175 (2): 1164–79. <a href="https://doi.org/10.1016/j.ejor.2005.06.011" class="external-link">https://doi.org/10.1016/j.ejor.2005.06.011</a>.
</div>
<div id="ref-Puterman94" class="csl-entry">
Puterman, M. L. 1994. <em>Markov Decision Processes</em>. Wiley Series
in Probability and Mathematical Statistics. Wiley-Interscience.
</div>
<div id="ref-Tijms03" class="csl-entry">
Tijms, Henk. C. 2003. <em>A First Course in Stochastic Models</em>. John
Wiley &amp; Sons Ltd.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Lars Relund Nielsen.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
